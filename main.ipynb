{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebaaa055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexi\\.conda\\envs\\etf_analyzer\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Weight'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m isin, files \u001b[38;5;129;01min\u001b[39;00m amundi_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnav\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitoli\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m---> 43\u001b[0m         etf \u001b[38;5;241m=\u001b[39m \u001b[43mAmundiETF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnav_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitoli_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitoli\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m         ETF_list\u001b[38;5;241m.\u001b[39mappend(etf)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\FINANCE\\ETF_PORTFOLIO_ANALYZER\\src\\classes_etf.py:71\u001b[0m, in \u001b[0;36mAmundiETF.__init__\u001b[1;34m(self, titoli_path, nav_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholdings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\FINANCE\\ETF_PORTFOLIO_ANALYZER\\src\\classes_etf.py:91\u001b[0m, in \u001b[0;36mAmundiETF._parse_files\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitoli_path, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m---> 91\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_holdings_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamundi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mholdings \u001b[38;5;241m=\u001b[39m df\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\FINANCE\\ETF_PORTFOLIO_ANALYZER\\src\\classes_etf.py:108\u001b[0m, in \u001b[0;36mAmundiETF._clean_holdings_dataframe\u001b[1;34m(self, df, source)\u001b[0m\n\u001b[0;32m     95\u001b[0m column_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamundi\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodice ISIN\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     }\n\u001b[0;32m    105\u001b[0m }\n\u001b[0;32m    106\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mcolumn_mapping[source])\n\u001b[0;32m    107\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 108\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsset_Class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrency\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\alexi\\.conda\\envs\\etf_analyzer\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\alexi\\.conda\\envs\\etf_analyzer\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Weight'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.classes_etf import IShareETF, AmundiETF\n",
    "from src.functions import *\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from collections import defaultdict\n",
    "\n",
    "filepath =r\"C:\\Users\\alexi\\Documents\\FINANCE\\ETF_PORTFOLIO_ANALYZER\\etf_data\" #put the excel files downloaded from iShare in the data folder and begin\n",
    "if not os.path.exists(\"analysis_data\"):\n",
    "    os.makedirs(\"analysis_data\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ETF_list = []\n",
    "\n",
    "# Group Amundi files by ISIN\n",
    "amundi_files = defaultdict(dict)\n",
    "\n",
    "# Step 1: Sort all files in the folder\n",
    "for x in os.listdir(filepath):\n",
    "    full_path = os.path.join(filepath, x)\n",
    "\n",
    "    # iShares: handled one file per ETF\n",
    "    if \"ishare\" in x.lower() and x.endswith(\".xlsx\"):\n",
    "        etf = IShareETF(full_path)\n",
    "        ETF_list.append(etf)\n",
    "\n",
    "    # Amundi: collect both NAV and Holdings (Titoli)\n",
    "    elif \"amundi\" in x.lower() and x.endswith(\".csv\"):\n",
    "        fund_name, isin = parse_amundi_filename(x)\n",
    "        if \"nav\" in x.lower():\n",
    "            amundi_files[isin]['nav'] = full_path\n",
    "        elif \"titoli\" in x.lower():\n",
    "            amundi_files[isin]['titoli'] = full_path\n",
    "\n",
    "\n",
    "# Step 2: Instantiate AmundiETF only when both files are present\n",
    "for isin, files in amundi_files.items():\n",
    "    if 'nav' in files and 'titoli' in files:\n",
    "        etf = AmundiETF(nav_path=files['nav'], titoli_path=files['titoli'])\n",
    "        ETF_list.append(etf)\n",
    "    else:\n",
    "        print(f\"[!] Skipping Amundi ETF with ISIN {isin}: incomplete files ({files})\")\n",
    "\n",
    "\n",
    "# Dictionary to hold user input\n",
    "quotas_dict = {}\n",
    "\n",
    "def submit():\n",
    "    try:\n",
    "        for etf, entry in entries:\n",
    "            fund_name = etf.metadata.get('fund_name', 'Unnamed ETF')\n",
    "            value = int(entry.get()) if entry.get().strip() else 0\n",
    "            quotas_dict[fund_name] = value\n",
    "        messagebox.showinfo(\"Success\", \"Quotas saved!\")\n",
    "        root.destroy()\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Error\", \"Please enter valid integers only.\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Enter ETF Quotas\")\n",
    "\n",
    "entries = []\n",
    "for i, etf in enumerate(ETF_list):\n",
    "    fund_name = etf.metadata.get('fund_name', f'ETF_{i}')\n",
    "    tk.Label(root, text=f\"{fund_name}:\").grid(row=i, column=0, sticky='w')\n",
    "    entry = tk.Entry(root)\n",
    "    entry.grid(row=i, column=1)\n",
    "    entries.append((etf, entry))\n",
    "\n",
    "submit_btn = tk.Button(root, text=\"Submit\", command=submit)\n",
    "submit_btn.grid(row=len(ETF_list), column=0, columnspan=2, pady=10)\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "# Print the result\n",
    "print(\"Final quotas:\", quotas_dict)\n",
    "\n",
    "def compute_geographic_exposure(ETF_list, quotas_dict, plot=True, top_n=None):\n",
    "    \"\"\"\n",
    "    Computes the geographic exposure of a portfolio based on ETF holdings and quotas.\n",
    "\n",
    "    Parameters:\n",
    "        ETF_list (list): List of ETF objects, each with `.metadata` and `.holdings`.\n",
    "        quotas_dict (dict): Dictionary with ETF fund names as keys and quota counts as values.\n",
    "        plot (bool): Whether to plot a pie chart of the exposure.\n",
    "        top_n (int or None): If set, shows only top N locations and groups others into \"Other\".\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Geographic exposure percentages indexed by location.\n",
    "    \"\"\"\n",
    "    portfolio_dfs = []\n",
    "\n",
    "    for etf in ETF_list:\n",
    "        fund_name = etf.metadata['fund_name']\n",
    "        if fund_name not in quotas_dict:\n",
    "            continue\n",
    "\n",
    "        quota = quotas_dict[fund_name]\n",
    "        price = etf.metadata['curr_value']\n",
    "        df = etf.holdings.copy()\n",
    "\n",
    "        total_value = quota * price\n",
    "\n",
    "        df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce')\n",
    "        df['€ Exposure'] = df['Weight'] / 100 * total_value\n",
    "\n",
    "        # Filter out rows with invalid or negative exposure\n",
    "        df = df[df['€ Exposure'].notna() & (df['€ Exposure'] >= 0)]\n",
    "\n",
    "        df['Location'] = df['Location'].fillna('Unknown')\n",
    "        portfolio_dfs.append(df[['Location', '€ Exposure']])\n",
    "\n",
    "    if not portfolio_dfs:\n",
    "        raise ValueError(\"No ETF data matched the provided quotas_dict keys.\")\n",
    "\n",
    "    # Combine and group\n",
    "    full_portfolio = pd.concat(portfolio_dfs)\n",
    "    exposure = full_portfolio.groupby('Location')['€ Exposure'].sum()\n",
    "    total_investment = exposure.sum()\n",
    "    exposure_percent = (exposure / total_investment * 100).sort_values(ascending=False)\n",
    "\n",
    "    # Optional: reduce to top N\n",
    "    if top_n is not None and top_n < len(exposure_percent):\n",
    "        others = exposure_percent.iloc[top_n:].sum()\n",
    "        exposure_percent = exposure_percent.iloc[:top_n].copy()\n",
    "        exposure_percent['Other'] = others\n",
    "\n",
    "    if plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        labels = exposure_percent.index\n",
    "        sizes = exposure_percent.values\n",
    "\n",
    "        # Define explode only for the 'Other' slice to make it stand out\n",
    "        explode = [0.05 if label == 'Other' else 0 for label in labels]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 9))\n",
    "        wedges, texts, autotexts = ax.pie(\n",
    "            sizes,\n",
    "            labels=labels,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=140,\n",
    "            explode=explode,\n",
    "            shadow=True,\n",
    "            textprops={'fontsize': 10},\n",
    "            wedgeprops={'edgecolor': 'white'}\n",
    "        )\n",
    "\n",
    "        ax.set_title('Geographic Exposure of Portfolio', fontsize=14, weight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return exposure_percent.round(2)\n",
    "\n",
    "exposure_percent=compute_geographic_exposure(ETF_list, quotas_dict, plot=True, top_n=None)\n",
    "exposure_percent.to_csv(\"analysis_data/geographic_exposure.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d93f02",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etf_analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
